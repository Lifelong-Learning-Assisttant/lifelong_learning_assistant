{"question": "Что такое линейная модель и почему она называется линейной?", "answer": "Линейная модель - это модель вида y = w^T x + b, где y - целевая переменная, x - вектор признаков, w - вектор весов, b - свободный коэффициент (bias). Модель называется линейной, потому что она является линейной функцией по признакам объекта.", "topic": "linear_models"}
{"question": "Какие основные преимущества линейных моделей?", "answer": "Основные преимущества: 1) Простота и интерпретируемость - можно понять влияние каждого признака на результат, 2) Быстрое обучение и применение, 3) Хорошо работают на небольших датасетах, 4) Веса модели имеют прозрачную интерпретацию.", "topic": "linear_models"}
{"question": "Что такое one-hot encoding и зачем он нужен?", "answer": "One-hot encoding - это способ кодирования категориальных признаков. Признак с k значениями заменяется на k бинарных признаков, где единица стоит только на позиции соответствующего значения. Обычно один признак выкидывают, чтобы избежать линейной зависимости.", "topic": "linear_models"}
{"question": "Что такое метод наименьших квадратов (МНК)?", "answer": "МНК - это метод для решения задачи линейной регрессии, который минимизирует сумму квадратов отклонений предсказаний от истинных значений: L(w) = ||Xw - y||^2. Имеет аналитическое решение w = (X^T X)^(-1) X^T y.", "topic": "linear_models"}
{"question": "В чём разница между градиентным спуском и стохастическим градиентным спуском?", "answer": "Градиентный спуск вычисляет градиент по всей выборке на каждом шаге (сложность O(nd)). Стохастический градиентный спуск (SGD) вычисляет градиент по мини-батчу объектов, что быстрее и позволяет работать с данными, не помещающимися в память.", "topic": "optimization"}
{"question": "Что такое регуляризация и зачем она нужна?", "answer": "Регуляризация - это добавление штрафа на сложность модели в функцию потерь для предотвращения переобучения. Основные виды: L1 (сумма модулей весов) и L2 (сумма квадратов весов). L2 предотвращает большие веса, L1 приводит к разреженности.", "topic": "regularization"}
{"question": "Чем отличается L1 и L2 регуляризация?", "answer": "L2 регуляризация (Ridge) добавляет ||w||^2, делает веса маленькими, но не обнуляет их. L1 регуляризация (Lasso) добавляет ||w||_1, приводит к разреженности - многие веса становятся нулевыми, что позволяет автоматически отбирать признаки.", "topic": "regularization"}
{"question": "Что такое логистическая регрессия?", "answer": "Логистическая регрессия - это метод бинарной классификации, который предсказывает вероятность принадлежности к классу через сигмоиду: P(y=1|x) = σ(w^T x), где σ(z) = 1/(1+e^(-z)). Обучается максимизацией правдоподобия (минимизацией кросс-энтропии).", "topic": "linear_models"}
{"question": "Что такое SVM и в чём его особенность?", "answer": "SVM (Support Vector Machine) - метод классификации, который ищет разделяющую гиперплоскость с максимальным отступом. Использует hinge loss и определяется только опорными векторами - ближайшими к границе объектами. Обладает доказуемой оптимальностью.", "topic": "linear_models"}
{"question": "Как работает многоклассовая классификация в линейных моделях?", "answer": "Два основных подхода: 1) One-vs-All - обучается K классификаторов, каждый отделяет один класс от остальных, 2) All-vs-All - обучается K(K-1)/2 классификаторов для каждой пары классов. Также есть многоклассовая логистическая регрессия с softmax.", "topic": "linear_models"}
{"question": "Что такое нейронная сеть?", "answer": "Нейронная сеть - это композиция простых функций (слоёв), каждый из которых применяет линейное преобразование и нелинейную функцию активации. Позволяет аппроксимировать сложные нелинейные зависимости и обучается методом обратного распространения ошибки.", "topic": "neural_networks"}
{"question": "Что такое функция активации и зачем она нужна?", "answer": "Функция активации - это нелинейная функция, применяемая после линейного преобразования в нейронной сети. Без неё сеть была бы эквивалентна линейной модели. Популярные активации: ReLU, sigmoid, tanh, GELU.", "topic": "neural_networks"}
{"question": "Что такое метод обратного распространения ошибки?", "answer": "Backpropagation - это эффективный алгоритм вычисления градиентов функции потерь по всем параметрам нейросети. Использует правило дифференцирования сложной функции и динамическое программирование для переиспользования промежуточных вычислений.", "topic": "neural_networks"}
{"question": "Что такое batch normalization?", "answer": "Batch normalization - это нормализация активаций по батчу: вычитается среднее и делится на стандартное отклонение. Стабилизирует обучение, позволяет использовать больший learning rate и служит регуляризацией. Применяется перед или после активации.", "topic": "neural_networks"}
{"question": "Что такое dropout и как он работает?", "answer": "Dropout - это метод регуляризации, при котором на каждой итерации обучения случайно выключается часть нейронов (обнуляются их выходы) с вероятностью p. При инференсе все нейроны активны, но их выходы умножаются на (1-p). Предотвращает переобучение.", "topic": "neural_networks"}
{"question": "Что такое свёртка в нейронных сетях?", "answer": "Свёртка (convolution) - это операция, применяющая ядро (фильтр) к локальным областям входа. Для изображений это окно kxk, которое скользит по изображению. Свёртка обеспечивает инвариантность к сдвигам и уменьшает число параметров по сравнению с полносвязными слоями.", "topic": "cnn"}
{"question": "Что такое receptive field?", "answer": "Receptive field - это область входного изображения, которая влияет на активацию конкретного нейрона. При последовательном применении свёрток receptive field растёт: для двух свёрток 3x3 он равен 5x5, для трёх - 7x7.", "topic": "cnn"}
{"question": "Что такое max pooling и зачем он нужен?", "answer": "Max pooling - это операция понижения разрешения, которая берёт максимум в окне (обычно 2x2) с шагом 2. Уменьшает размер карт признаков в 2 раза, увеличивает receptive field и добавляет инвариантность к небольшим сдвигам.", "topic": "cnn"}
{"question": "Что такое global average pooling?", "answer": "Global average pooling - это усреднение всех активаций вдоль пространственных измерений. Превращает тензор HxWxC в вектор длины C. Позволяет работать с изображениями любого размера и радикально уменьшает число параметров по сравнению с flatten + FC.", "topic": "cnn"}
{"question": "Что такое residual connection?", "answer": "Residual connection (skip connection) - это прямое соединение, прибавляющее вход блока к его выходу: y = F(x) + x. Позволяет градиентам проходить напрямую через сеть, решая проблему затухающих градиентов. Ключевая идея архитектуры ResNet.", "topic": "cnn"}
{"question": "Что такое решающее дерево?", "answer": "Решающее дерево - это модель, которая принимает решения с помощью последовательности простых правил (предикатов). Во внутренних узлах проверяются условия вида x_j <= t, в листьях записаны предсказания. Осуществляет кусочно-постоянную аппроксимацию.", "topic": "decision_trees"}
{"question": "Почему построение оптимального дерева - NP-полная задача?", "answer": "Поиск дерева минимальной глубины с оптимальным качеством на обучающей выборке - NP-полная задача. Поэтому используют жадные алгоритмы: строят дерево уровень за уровнем, на каждом шаге выбирая локально лучший сплит.", "topic": "decision_trees"}
{"question": "Что такое критерий информативности (impurity)?", "answer": "Информативность - это мера однородности объектов в листе. Для регрессии с MSE это дисперсия таргетов. Для классификации используют энтропию или критерий Джини. Чем ниже информативность, тем лучше объекты в листе приближаются константой.", "topic": "decision_trees"}
{"question": "Что такое энтропия в контексте деревьев решений?", "answer": "Энтропия H = -Σ p_k log(p_k) измеряет неопределённость распределения классов в узле. Максимальна для равномерного распределения, минимальна (0) для вырожденного. Используется как критерий информативности при построении деревьев.", "topic": "decision_trees"}
{"question": "Что такое критерий Джини?", "answer": "Критерий Джини G = Σ p_k(1 - p_k) = 1 - Σ p_k^2 - альтернатива энтропии для измерения неоднородности. Равен вероятности ошибочной классификации при случайном присвоении меток. Обычно работает похоже на энтропию, но вычисляется быстрее.", "topic": "decision_trees"}
{"question": "Как деревья работают с категориальными признаками?", "answer": "Для категориальных признаков можно рассматривать сплиты вида x_j ∈ S. Для бинарной классификации значения можно упорядочить по доле класса 1, для регрессии с MSE - по среднему таргету. Тогда задача сводится к поиску порога на упорядоченных значениях.", "topic": "decision_trees"}
{"question": "Как деревья обрабатывают пропуски в данных?", "answer": "При обучении объекты с пропусками игнорируются при выборе сплита, но затем отправляются в оба поддерева с весами. При применении объект с пропуском идёт в обе ветки, предсказания усредняются с теми же весами. Альтернатива - ввести категорию 'missing'.", "topic": "decision_trees"}
{"question": "Что такое гистограммный метод построения деревьев?", "answer": "Гистограммный метод дискретизирует признаки на B корзин (обычно 256) перед обучением. Вместо перебора всех N значений перебирается только B границ корзин. Ускоряет построение дерева с O(Nd log N) до O(Nd + NB), где обычно B << N.", "topic": "decision_trees"}
{"question": "Какие методы регуляризации используются для деревьев?", "answer": "Основные методы: 1) ограничение максимальной глубины, 2) минимальное число объектов в листе, 3) максимальное число листьев, 4) требование минимального улучшения качества при сплите. Также используют pre-pruning (early stopping) и post-pruning (обрезка после построения).", "topic": "decision_trees"}
{"question": "Что такое градиентный бустинг?", "answer": "Градиентный бустинг - это ансамблевый метод, который последовательно строит композицию базовых алгоритмов (обычно деревьев). Каждый новый алгоритм обучается приближать антиградиент функции потерь по предсказаниям текущей композиции.", "topic": "gradient_boosting"}
{"question": "Как работает градиентный бустинг интуитивно?", "answer": "Аналогия с гольфистом: каждый удар (базовый алгоритм) корректирует текущее положение мяча (предсказание), приближая его к лунке (истинному значению). Каждый следующий алгоритм исправляет ошибки предыдущих, постепенно улучшая композицию.", "topic": "gradient_boosting"}
{"question": "Почему в градиентном бустинге используется антиградиент?", "answer": "Антиградиент функции потерь по текущим предсказаниям указывает направление наискорейшего убывания функции потерь. Обучая базовый алгоритм приближать антиградиент, мы делаем шаг в направлении уменьшения ошибки всей композиции.", "topic": "gradient_boosting"}
{"question": "Что такое learning rate в градиентном бустинге?", "answer": "Learning rate (темп обучения) η - это коэффициент, на который умножается вклад каждого базового алгоритма: F_m = F_{m-1} + η * h_m. Меньший η требует больше итераций, но даёт более стабильное обучение и лучшую регуляризацию.", "topic": "gradient_boosting"}
{"question": "Чем отличаются формы деревьев в LightGBM, XGBoost и CatBoost?", "answer": "LightGBM: несимметричные деревья, делит вершину с лучшим скором. XGBoost: симметричные по глубине, строит уровень за уровнем. CatBoost: обливиозные деревья, все вершины уровня имеют одинаковый предикат. CatBoost наиболее регуляризован, LightGBM наиболее гибок.", "topic": "gradient_boosting"}
{"question": "Что такое feature importance в градиентном бустинге?", "answer": "Feature importance - это оценка важности признаков. Метод MDI (mean decrease in impurity) считает среднюю долю объектов, для которых происходило ветвление по признаку. Чем выше в дереве признак, тем больше его важность.", "topic": "gradient_boosting"}
{"question": "Где используется градиентный бустинг?", "answer": "Градиентный бустинг - стандарт для табличных данных: ранжирование в поиске, рекомендательные системы, таргетирование рекламы, предсказание погоды, выбор пункта назначения такси. Не так хорош на однородных данных (тексты, изображения), где лучше работают нейросети.", "topic": "gradient_boosting"}
{"question": "Что такое кластеризация?", "answer": "Кластеризация - это задача обучения без учителя, которая разбивает объекты на группы (кластеры) так, чтобы похожие объекты оказались в одном кластере. В отличие от классификации, классы заранее не заданы и определяются самим алгоритмом.", "topic": "clustering"}
{"question": "Как работает метод K-means?", "answer": "K-means итеративно повторяет два шага: 1) отнесение каждого объекта к ближайшему центру кластера, 2) пересчёт центров как среднего арифметического объектов кластера. Продолжается до сходимости. Минимизирует сумму квадратов расстояний до центров.", "topic": "clustering"}
{"question": "Что такое K-means++ и зачем он нужен?", "answer": "K-means++ - это улучшенная инициализация центров для K-means. Первый центр выбирается случайно, каждый следующий - с вероятностью, пропорциональной квадрату расстояния до ближайшего центра. Это разносит начальные центры и улучшает сходимость.", "topic": "clustering"}
{"question": "Что такое иерархическая кластеризация?", "answer": "Иерархическая кластеризация строит дерево кластеров. Агломеративный подход начинает с N кластеров (по объекту) и итеративно объединяет два ближайших. Результат визуализируется дендрограммой. Позволяет получить кластеризацию на любом уровне детализации.", "topic": "clustering"}
{"question": "Как измеряется расстояние между кластерами?", "answer": "Основные способы: 1) single linkage - минимальное расстояние между объектами, 2) complete linkage - максимальное расстояние, 3) average linkage - среднее расстояние, 4) Ward distance - увеличение дисперсии при объединении. Выбор влияет на форму получаемых кластеров.", "topic": "clustering"}
{"question": "Как работает алгоритм DBSCAN?", "answer": "DBSCAN выделяет кластеры на основе плотности. Точки делятся на core (≥minPts соседей в радиусе ε), border (есть core-сосед) и noise. Core-точки с общей окрестностью соединяются рёбрами, выделяются компоненты связности. Автоматически определяет число кластеров.", "topic": "clustering"}
{"question": "Что такое коэффициент силуэта?", "answer": "Коэффициент силуэта для объекта: s = (b-a)/max(a,b), где a - среднее расстояние до объектов своего кластера, b - до объектов ближайшего другого кластера. Значения от -1 до +1. Средний силуэт по выборке - метрика качества кластеризации без разметки.", "topic": "clustering"}
{"question": "Что такое гомогенность и полнота кластеризации?", "answer": "Гомогенность: каждый кластер содержит объекты только одного класса (H = 1 - H(C|K)/H(C)). Полнота: все объекты класса в одном кластере (C = 1 - H(K|C)/H(K)). V-мера - их среднее гармоническое. Требуют разметки для оценки.", "topic": "clustering"}
{"question": "Что такое трансформер?", "answer": "Трансформер - это архитектура нейросети, основанная на механизме self-attention. Позволяет каждому элементу последовательности напрямую взаимодействовать с каждым, в отличие от RNN. Состоит из энкодера и декодера с multi-head attention и feed-forward слоями.", "topic": "transformers"}
{"question": "Как работает механизм attention?", "answer": "Attention вычисляет для каждого элемента три вектора: query (Q), key (K), value (V). Близость query к key определяет вес: Attention(Q,K,V) = softmax(QK^T/√d_k)V. Каждый элемент получает взвешенную сумму values, где веса зависят от близости к другим элементам.", "topic": "transformers"}
{"question": "Что такое multi-head attention?", "answer": "Multi-head attention применяет несколько параллельных механизмов attention с разными весовыми матрицами Q, K, V. Это позволяет модели учитывать разные типы зависимостей между токенами. Результаты конкатенируются и проецируются линейным слоем.", "topic": "transformers"}
{"question": "Зачем нужны позиционные эмбеддинги?", "answer": "Операции в трансформере инвариантны к порядку элементов. Позиционные эмбеддинги добавляются к эмбеддингам токенов, чтобы модель могла различать позиции. Могут быть фиксированными (синусоиды) или обучаемыми, абсолютными или относительными.", "topic": "transformers"}
{"question": "Чем отличаются BERT и GPT?", "answer": "GPT - автоРегрессивная модель (декодер), предсказывает следующий токен, использует каузальную маску (видит только прошлое). BERT - bidirectional энкодер, видит всю последовательность, обучается на masked language modeling. GPT для генерации, BERT для понимания текста.", "topic": "transformers"}
{"question": "Что такое каузальная маска в трансформерах?", "answer": "Каузальная (авторегрессивная) маска - это нижнетреугольная матрица, которая обнуляет веса attention для будущих токенов. Нужна в декодере, чтобы при обучении токен не видел последующие токены, иначе будет утечка информации.", "topic": "transformers"}
{"question": "Что такое градиентный спуск?", "answer": "Градиентный спуск - это итеративный метод оптимизации, который обновляет параметры в направлении антиградиента: w_{t+1} = w_t - α∇L(w_t), где α - learning rate. Антиградиент указывает направление наискорейшего убывания функции.", "topic": "optimization"}
{"question": "Что такое momentum в оптимизации?", "answer": "Momentum добавляет инерцию в градиентный спуск: v_t = βv_{t-1} + ∇L, w_t = w_{t-1} - αv_t. Накапливает экспоненциально взвешенную сумму градиентов. Ускоряет сходимость в направлениях с постоянным градиентом и сглаживает осцилляции.", "topic": "optimization"}
{"question": "Как работает метод AdaGrad?", "answer": "AdaGrad адаптирует learning rate для каждого параметра: w_t = w_{t-1} - α/√(G_t + ε) * g_t, где G_t = Σg_i^2 - сумма квадратов градиентов. Параметры с большими градиентами получают меньший learning rate. Хорош для разреженных данных.", "topic": "optimization"}
{"question": "Что такое RMSprop?", "answer": "RMSprop - модификация AdaGrad с экспоненциальным скользящим средним: G_t = βG_{t-1} + (1-β)g_t^2. Позволяет 'забывать' старые градиенты, решая проблему бесконечного накопления в AdaGrad. Learning rate не монотонно убывает.", "topic": "optimization"}
{"question": "Как работает оптимизатор Adam?", "answer": "Adam комбинирует momentum и RMSprop: m_t = β_1m_{t-1} + (1-β_1)g_t (momentum), v_t = β_2v_{t-1} + (1-β_2)g_t^2 (RMSprop). Использует bias correction: m̂ = m/(1-β_1^t), v̂ = v/(1-β_2^t). Обновление: w = w - α*m̂/√(v̂+ε).", "topic": "optimization"}
{"question": "Что такое bias correction в Adam?", "answer": "Bias correction корректирует смещение в начале обучения: m̂ = m/(1-β_1^t), v̂ = v/(1-β_2^t). Без неё m и v смещены к нулю в начале (при β_1=0.9, m_1 = 0.1*g_1, смещение в 10 раз). Correction особенно важна в первые итерации.", "topic": "optimization"}
{"question": "Что такое AMSGrad?", "answer": "AMSGrad - модификация Adam, которая исправляет проблему с отрицательными регуляризаторами. Использует v̂_t = max(v̂_{t-1}, v_t) вместо просто v_t. Гарантирует монотонное убывание learning rate, улучшает сходимость на поздних стадиях обучения.", "topic": "optimization"}
{"question": "Что такое learning rate scheduling?", "answer": "Learning rate scheduling - это изменение learning rate в процессе обучения. Learning rate decay (уменьшение) помогает сходимости. Warm restart (резкое увеличение) помогает выйти из локальных минимумов. Популярные стратегии: step decay, exponential decay, cosine annealing.", "topic": "optimization"}
{"question": "Что такое accuracy?", "answer": "Accuracy - доля правильно классифицированных объектов: (TP+TN)/(TP+TN+FP+FN). Простая и понятная метрика, но не учитывает дисбаланс классов и разную цену ошибок на разных классах.", "topic": "metrics"}
{"question": "Что такое precision и recall?", "answer": "Precision (точность) = TP/(TP+FP) - доля истинно положительных среди предсказанных положительными. Recall (полнота) = TP/(TP+FN) - доля найденных положительных из всех положительных. Precision важна, когда дорого FP, recall - когда дорого FN.", "topic": "metrics"}
{"question": "Что такое F1-мера?", "answer": "F1-мера - это среднее гармоническое precision и recall: F1 = 2*P*R/(P+R). Компромисс между точностью и полнотой. Обобщение F_β = (1+β²)*P*R/(β²*P+R) позволяет задать относительную важность precision и recall.", "topic": "metrics"}
{"question": "Что такое ROC-кривая и AUC?", "answer": "ROC-кривая показывает зависимость TPR (recall) от FPR при варьировании порога классификации. AUC (area under curve) - площадь под ROC-кривой, равна вероятности правильного упорядочивания случайной пары (объект класса 1, объект класса 0).", "topic": "metrics"}
{"question": "Что такое confusion matrix?", "answer": "Confusion matrix (матрица ошибок) - таблица 2x2 для бинарной классификации: TP (верно предсказан +), FP (ошибочно предсказан +), TN (верно предсказан -), FN (ошибочно предсказан -). Даёт полную картину ошибок классификатора.", "topic": "metrics"}
{"question": "Что такое MSE и RMSE?", "answer": "MSE (Mean Squared Error) = (1/n)Σ(y_i - ŷ_i)² - среднеквадратичная ошибка. RMSE = √MSE - корень из MSE, имеет ту же размерность, что и таргет. Квадратично штрафует большие ошибки, чувствительна к выбросам.", "topic": "metrics"}
{"question": "Что такое MAE?", "answer": "MAE (Mean Absolute Error) = (1/n)Σ|y_i - ŷ_i| - средняя абсолютная ошибка. Менее чувствительна к выбросам, чем MSE. Оптимальное константное предсказание - медиана (для MSE - среднее).", "topic": "metrics"}
{"question": "Что такое MAPE и SMAPE?", "answer": "MAPE (Mean Absolute Percentage Error) = (1/n)Σ|y_i - ŷ_i|/|y_i| - относительная ошибка. Делает объекты равнозначными независимо от масштаба. SMAPE = (1/n)Σ|y_i - ŷ_i|/(|y_i|+|ŷ_i|) - симметричная версия, избегает деления на ноль.", "topic": "metrics"}
{"question": "Что такое R² (коэффициент детерминации)?", "answer": "R² = 1 - SS_res/SS_tot, где SS_res = Σ(y_i - ŷ_i)², SS_tot = Σ(y_i - ȳ)². Показывает долю дисперсии таргета, объяснённую моделью. R²=1 для идеальной модели, R²=0 для константного предсказания среднего.", "topic": "metrics"}
{"question": "Что такое переобучение?", "answer": "Переобучение (overfitting) - ситуация, когда модель слишком хорошо подстраивается под обучающую выборку, запоминая шум и выбросы, но плохо обобщается на новые данные. Проявляется как большая разница между качеством на train и test.", "topic": "ml_basics"}
{"question": "Что такое bias-variance tradeoff?", "answer": "Ошибка модели раскладывается на три компоненты: bias² (систематическая ошибка, недообучение), variance (чувствительность к выборке, переобучение) и irreducible error (шум). Сложные модели имеют низкий bias, но высокий variance. Нужен баланс.", "topic": "ml_basics"}
{"question": "Что такое кросс-валидация?", "answer": "Кросс-валидация - метод оценки качества модели. K-fold CV: выборка делится на K частей, модель обучается K раз на K-1 частях и тестируется на оставшейся. Итоговая оценка - среднее по K фолдам. Даёт более надёжную оценку, чем один train/test split.", "topic": "ml_basics"}
{"question": "Что такое ансамбль моделей?", "answer": "Ансамбль - это комбинация нескольких моделей для улучшения качества. Основные подходы: bagging (параллельное обучение на разных подвыборках, усреднение), boosting (последовательное обучение, каждая модель исправляет ошибки предыдущих), stacking (мета-модель на предсказаниях базовых).", "topic": "ensembles"}
{"question": "Что такое bagging?", "answer": "Bagging (Bootstrap AGGregatING) - обучение нескольких моделей на bootstrap-выборках (случайные подвыборки с возвращением) и усреднение их предсказаний. Уменьшает variance, не увеличивая bias. Случайный лес - пример bagging для деревьев.", "topic": "ensembles"}
{"question": "Что такое случайный лес?", "answer": "Случайный лес (Random Forest) - ансамбль решающих деревьев, обученных на bootstrap-выборках. При каждом сплите рассматривается только случайное подмножество признаков (обычно √d). Это добавляет разнообразия деревьям и улучшает обобщающую способность.", "topic": "ensembles"}
{"question": "Что такое feature engineering?", "answer": "Feature engineering - создание новых признаков из существующих для улучшения качества модели. Включает: преобразования (логарифм, степени), комбинации признаков, агрегации, извлечение признаков из текста/дат, кодирование категориальных переменных.", "topic": "ml_basics"}
{"question": "Что такое dimensionality reduction?", "answer": "Dimensionality reduction - снижение размерности данных с сохранением важной информации. Методы: PCA (линейные проекции максимальной дисперсии), t-SNE (нелинейное вложение для визуализации), автоэнкодеры (нейросетевое сжатие). Ускоряет обучение и помогает визуализации.", "topic": "ml_basics"}
{"question": "Что такое PCA?", "answer": "PCA (Principal Component Analysis) - метод линейного снижения размерности. Находит ортогональные направления максимальной дисперсии данных (главные компоненты). Проецирование на первые k компонент даёт наилучшее k-мерное линейное приближение в смысле MSE.", "topic": "dimensionality_reduction"}
{"question": "Что такое batch size в обучении нейросетей?", "answer": "Batch size - количество объектов, на которых вычисляется градиент за один шаг оптимизации. Маленький batch: больше шумный градиент, быстрее итерации, лучше регуляризация. Большой batch: точнее градиент, эффективнее на GPU, но может хуже обобщаться.", "topic": "neural_networks"}
{"question": "Что такое эпоха в машинном обучении?", "answer": "Эпоха (epoch) - один полный проход по всей обучающей выборке. При batch size < N одна эпоха включает N/batch_size итераций градиентного спуска. Обычно модели обучаются несколько эпох до сходимости или срабатывания early stopping.", "topic": "ml_basics"}
{"question": "Что такое early stopping?", "answer": "Early stopping - остановка обучения, когда качество на валидационной выборке перестаёт улучшаться. Предотвращает переобучение. Обычно ждут несколько эпох без улучшения (patience), затем останавливают и возвращают лучшие веса.", "topic": "regularization"}
{"question": "Что такое data augmentation?", "answer": "Data augmentation - искусственное увеличение обучающей выборки применением преобразований, сохраняющих метку. Для изображений: повороты, отражения, сдвиги, изменение яркости, cutout. Для текстов: синонимы, back-translation. Мощный метод регуляризации.", "topic": "regularization"}
{"question": "Что такое label smoothing?", "answer": "Label smoothing - замена one-hot меток на сглаженные: вместо [0,1,0] используют [ε/K, 1-ε+ε/K, ε/K]. Предотвращает слишком уверенные предсказания, улучшает калибровку вероятностей, служит регуляризацией. Обычно ε=0.1.", "topic": "regularization"}
{"question": "Что такое mixup?", "answer": "Mixup - метод аугментации, создающий виртуальные примеры линейной интерполяцией: x̃ = λx_i + (1-λ)x_j, ỹ = λy_i + (1-λ)y_j, где λ~Beta(α,α). Заставляет модель вести себя линейно между примерами, улучшает обобщение и устойчивость.", "topic": "regularization"}
{"question": "Что такое transfer learning?", "answer": "Transfer learning - использование модели, предобученной на большом датасете, для новой задачи. Обычно заменяют последний слой и дообучают (fine-tuning). Позволяет получить хорошее качество на малых данных, используя знания из предобучения.", "topic": "ml_basics"}
{"question": "Что такое fine-tuning?", "answer": "Fine-tuning - дообучение предобученной модели на новой задаче. Обычно используют маленький learning rate, чтобы не разрушить предобученные веса. Можно замораживать (freeze) ранние слои и обучать только последние, постепенно размораживая больше слоёв.", "topic": "ml_basics"}
{"question": "Что такое embedding?", "answer": "Embedding - плотное векторное представление объекта (слова, пользователя, товара) в низкоразмерном пространстве. Обучается так, чтобы похожие объекты имели близкие вектора. Примеры: Word2Vec, GloVe для слов, эмбеддинги в рекомендательных системах.", "topic": "ml_basics"}
{"question": "Что такое attention mechanism в общем смысле?", "answer": "Attention - механизм, позволяющий модели фокусироваться на релевантных частях входа. Вычисляет веса важности для разных частей, делает взвешенную сумму. Используется не только в трансформерах, но и в seq2seq, image captioning и других задачах.", "topic": "neural_networks"}
{"question": "Что такое seq2seq модель?", "answer": "Seq2seq (sequence-to-sequence) - архитектура для преобразования одной последовательности в другую (перевод, суммаризация). Состоит из энкодера (кодирует вход в вектор контекста) и декодера (генерирует выход). Часто использует attention для связи энкодера и декодера.", "topic": "neural_networks"}
{"question": "Что такое gradient clipping?", "answer": "Gradient clipping - ограничение нормы градиента для предотвращения взрывающихся градиентов. Если ||g|| > threshold, масштабируем: g = threshold * g/||g||. Стабилизирует обучение RNN и глубоких сетей. Альтернатива - clipping по значению: g = clip(g, -c, c).", "topic": "optimization"}
{"question": "Что такое weight decay?", "answer": "Weight decay - добавление L2-регуляризации через прямое уменьшение весов: w = w - α(∇L + λw) = (1-αλ)w - α∇L. Эквивалентно L2-регуляризации для SGD, но отличается для Adam. Decoupled weight decay (AdamW) применяет decay отдельно от градиента.", "topic": "regularization"}
{"question": "Что такое learning rate warmup?", "answer": "Learning rate warmup - постепенное увеличение learning rate от малого значения до целевого в начале обучения. Стабилизирует обучение больших моделей (особенно трансформеров) с большими batch size. После warmup обычно применяют decay.", "topic": "optimization"}
{"question": "Что такое curriculum learning?", "answer": "Curriculum learning - обучение от простых примеров к сложным, имитируя человеческое обучение. Сначала модель обучается на лёгких примерах, постепенно добавляются более сложные. Может ускорить сходимость и улучшить качество на сложных задачах.", "topic": "ml_basics"}
{"question": "Что такое self-supervised learning?", "answer": "Self-supervised learning - обучение без размеченных данных, где метки генерируются автоматически из самих данных. Примеры: предсказание следующего слова (GPT), восстановление замаскированных слов (BERT), предсказание поворота изображения. Используется для предобучения.", "topic": "ml_basics"}
{"question": "Что такое contrastive learning?", "answer": "Contrastive learning - обучение представлений через сравнение: похожие примеры (positive pairs) должны быть близки в пространстве эмбеддингов, непохожие (negative pairs) - далеки. Примеры: SimCLR, MoCo. Ключевая идея: учиться различать без явных меток.", "topic": "ml_basics"}
{"question": "Что такое few-shot learning?", "answer": "Few-shot learning - обучение на очень малом количестве примеров (1-5 на класс). Подходы: meta-learning (учимся учиться на разных задачах), transfer learning (предобучение + fine-tuning), metric learning (обучение метрики близости). Актуально для редких классов.", "topic": "ml_basics"}
{"question": "Что такое zero-shot learning?", "answer": "Zero-shot learning - классификация объектов классов, не встречавшихся при обучении. Использует вспомогательную информацию: описания классов, атрибуты, связи в онтологии. Модель учится связывать визуальные признаки с семантическими описаниями. Пример: CLIP.", "topic": "ml_basics"}
{"question": "Чем Adaptive FTRL отличается от классического градиентного спуска?", "answer": "Adaptive FTRL использует адаптивные регуляризаторы, зависящие от истории итераций, что позволяет лучше контролировать сходимость и стабильность по сравнению с фиксированным шагом в классическом градиентном спуске.", "topic": "adaptive_ftrl"}
{"question": "Что такое FTRL-Proximal?", "answer": "FTRL-Proximal — это вариант FTRL, в котором регуляризатор центрирован в текущей точке решения, что обычно обеспечивает лучшую стабильность и практическую эффективность.", "topic": "adaptive_ftrl"}
{"question": "Что такое FTRL-Centered?", "answer": "FTRL-Centered — это вариант FTRL, в котором регуляризатор центрирован в фиксированной точке, например в нуле, и часто используется для введения глобальных ограничений.", "topic": "adaptive_ftrl"}
{"question": "Как FTRL связан со стохастическим градиентным спуском?", "answer": "Стохастический градиентный спуск с фиксированным или убывающим learning rate можно рассматривать как частный случай FTRL с определённым выбором регуляризатора.", "topic": "adaptive_ftrl"}
{"question": "Что такое Strong FTRL Lemma?", "answer": "Strong FTRL Lemma — это ключевой результат, дающий верхнюю оценку regret через регуляризацию в оптимальной точке и стабильность последовательных решений алгоритма.", "topic": "adaptive_ftrl"}
{"question": "Почему в практических реализациях Adaptive FTRL часто используют диагональные матрицы?", "answer": "Диагональные матрицы позволяют снизить вычислительную сложность и требования к памяти с квадратичных до линейных по числу параметров.", "topic": "adaptive_ftrl"}
{"question": "Как AdaGrad выводится из FTRL?", "answer": "AdaGrad возникает как FTRL-Proximal с диагональной адаптивной регуляризацией, настраиваемой по истории квадратов градиентов по каждой координате.", "topic": "adaptive_ftrl"}
{"question": "Чем regret-оценка AdaGrad лучше оценки обычного градиентного спуска?", "answer": "Оценка regret в AdaGrad адаптируется по координатам и зависит от суммы квадратов градиентов по каждой компоненте, а не от общей нормы градиента, что даёт улучшенную сходимость при разреженных или неоднородных данных.", "topic": "adaptive_ftrl"}
{"question": "Что такое Composite-Objective FTRL?", "answer": "Composite-Objective FTRL — это комбинация FTRL-Centered и FTRL-Proximal, позволяющая одновременно накладывать глобальные ограничения и сохранять локальную стабильность обновлений.", "topic": "adaptive_ftrl"}
{"question": "Зачем в FTRL используют линеаризацию функций потерь?", "answer": "Линеаризация функций потерь делает обновления вычислительно эффективными и аналитически вычислимыми, сохраняя при этом те же теоретические гарантии на regret.", "topic": "adaptive_ftrl"}
{"question": "Что показывает автокорреляционная функция временного ряда?", "answer": "Автокорреляционная функция показывает степень линейной зависимости между значениями временного ряда, разделёнными заданным лагом, то есть насколько значение в прошлом влияет на текущее значение.", "topic": "time_series_analysis"}
{"question": "Как интерпретировать значение автокорреляции, равное нулю?", "answer": "Значение автокорреляции, равное нулю, означает отсутствие линейной зависимости между значениями ряда с заданным лагом, но не гарантирует полной независимости этих значений.", "topic": "time_series_analysis"}
{"question": "Как проверить, является ли автокорреляция статистически значимой?", "answer": "Для проверки статистической значимости автокорреляции используется критерий Льюнга-Бокса: если p-value меньше заданного порога значимости (например, 0.05), автокорреляция считается значимой.", "topic": "time_series_analysis"}
{"question": "Что такое стационарный временной ряд в широком смысле?", "answer": "Стационарный временной ряд в широком смысле — это ряд с постоянным математическим ожиданием и автокорреляцией, зависящей только от расстояния между наблюдениями, а не от их конкретного времени.", "topic": "time_series_analysis"}
{"question": "Почему случайное блуждание не является стационарным рядом?", "answer": "Случайное блуждание нестационарно, потому что его дисперсия растёт со временем, несмотря на то что математическое ожидание может оставаться постоянным.", "topic": "time_series_analysis"}
{"question": "Какие преобразования применяются для приведения нестационарного ряда к стационарному?", "answer": "Для приведения ряда к стационарному применяют логарифмирование или преобразование Бокса-Кокса для стабилизации дисперсии, а также обычное и сезонное дифференцирование для устранения тренда и сезонности.", "topic": "time_series_analysis"}
{"question": "В чём смысл параметра сглаживания в модели простого экспоненциального сглаживания?", "answer": "Параметр сглаживания определяет, насколько сильно новое наблюдение влияет на сглаженное значение: при близком к единице сглаживание слабое, при близком к нулю — сильное.", "topic": "time_series_analysis"}
{"question": "Когда можно применять простое экспоненциальное сглаживание без потери информации?", "answer": "Простое экспоненциальное сглаживание можно применять без существенной потери информации, если временной ряд стационарен, то есть не содержит тренда и сезонности.", "topic": "time_series_analysis"}
{"question": "Чем модель Хольта отличается от простого экспоненциального сглаживания?", "answer": "Модель Хольта учитывает линейный тренд в данных, вводя дополнительное уравнение для оценки наклона тренда, тогда как простое экспоненциальное сглаживание подходит только для рядов без тренда.", "topic": "time_series_analysis"}
{"question": "Как работает адаптивное экспоненциальное сглаживание?", "answer": "Адаптивное экспоненциальное сглаживание динамически изменяет параметр сглаживания в зависимости от поведения ошибок прогноза, чтобы быстрее реагировать на структурные изменения в ряде.", "topic": "time_series_analysis"}
{"question": "Что такое bias-variance decomposition и зачем она нужна при анализе ансамблей?", "answer": "Bias-variance decomposition — это разложение ошибки модели на три компоненты: неустранимый шум, смещение (bias) и разброс (variance). Оно помогает понять, за счёт чего можно улучшить качество модели, и лежит в основе теории ансамблевых методов.", "topic": "ensembles"}
{"question": "В чём суть метода бэггинга?", "answer": "Бэггинг строит множество моделей, обучая каждую на случайной подвыборке с возвращением из исходной обучающей выборки, а затем усредняет их предсказания. Это уменьшает разброс ансамбля, не увеличивая смещение.", "topic": "ensembles"}
{"question": "Почему бэггинг снижает разброс, но не влияет на смещение?", "answer": "Поскольку все базовые модели обучаются одинаковым алгоритмом на выборках из одного распределения, их среднее предсказание остаётся тем же (смещение не меняется), но усреднение независимых ошибок уменьшает общую дисперсию предсказаний.", "topic": "ensembles"}
{"question": "Чем случайный лес отличается от обычного бэггинга над деревьями?", "answer": "Случайный лес дополнительно вводит случайность в выбор признаков при построении каждого сплита в деревьях, что снижает корреляцию между базовыми моделями и усиливает эффект ансамблирования.", "topic": "ensembles"}
{"question": "Какую глубину деревьев рекомендуется использовать в случайном лесу и почему?", "answer": "Рекомендуется использовать глубокие деревья, потому что бэггинг не снижает смещение, и чтобы общая ошибка была малой, нужно, чтобы базовые модели имели низкое смещение, что достигается за счёт их сложности.", "topic": "ensembles"}
{"question": "Сколько признаков обычно выбирают при построении одного дерева в случайном лесу?", "answer": "Для задач классификации обычно выбирают квадратный корень из общего числа признаков, а для регрессии — около одной трети всех признаков.", "topic": "ensembles"}
{"question": "В чём основное отличие бустинга от бэггинга?", "answer": "Бустинг обучает базовые модели последовательно, так что каждая следующая модель пытается исправить ошибки предыдущих, в то время как бэггинг обучает модели параллельно и независимо.", "topic": "ensembles"}
{"question": "Какие модели лучше использовать в качестве базовых в бустинге и почему?", "answer": "В бустинге лучше использовать простые модели с высоким смещением и низким разбросом, например, неглубокие деревья, потому что основная цель бустинга — снижение смещения, а обучение простых моделей быстрее.", "topic": "ensembles"}
{"question": "Что такое стекинг и чем он отличается от других ансамблевых методов?", "answer": "Стекинг объединяет разнородные базовые модели с помощью обучаемой мета-модели, которая принимает их предсказания как входные признаки, в отличие от простого усреднения или голосования в других методах.", "topic": "ensembles"}
{"question": "Зачем в стекинге используется кросс-валидация при формировании мета-признаков?", "answer": "Кросс-валидация предотвращает переобучение мета-модели, гарантируя, что мета-признаки для обучающих объектов получены моделями, не обучавшимися на этих же объектах.", "topic": "ensembles"}
{"question": "Как в байесовском подходе вводится априорное знание о параметрах модели?", "answer": "Априорное знание вводится через выбор априорного распределения на параметры модели, например, нормальное распределение для предположения, что веса малы по модулю.", "topic": "bayesian_approach"}
{"question": "Что такое апостериорное распределение и как оно связано с априорным?", "answer": "Апостериорное распределение — это обновлённое представление о параметрах модели после учёта данных, полученное из априорного распределения с помощью формулы Байеса.", "topic": "bayesian_approach"}
{"question": "Что означает, что два распределения являются сопряжёнными?", "answer": "Сопряжённые распределения — это такие пары априорного и правдоподобия, для которых апостериорное распределение принадлежит тому же семейству, что и априорное.", "topic": "bayesian_approach"}
{"question": "Что такое MAP-оценка и чем она отличается от MLE?", "answer": "MAP-оценка — это точка максимума апостериорного распределения, учитывающая априорное знание, в то время как MLE основана только на данных и игнорирует априорную информацию.", "topic": "bayesian_approach"}
{"question": "Как байесовский подход объясняет L2-регуляризацию в линейной регрессии?", "answer": "L2-регуляризация соответствует использованию гауссовского (нормального) априорного распределения на веса, которое штрафует большие значения коэффициентов.", "topic": "bayesian_approach"}
{"question": "Как байесовский подход объясняет L1-регуляризацию в линейной регрессии?", "answer": "L1-регуляризация соответствует использованию лапласовского априорного распределения на веса, которое способствует разреженности решения, делая многие веса близкими к нулю.", "topic": "bayesian_approach"}
{"question": "Как делается предсказание в байесовском подходе для нового объекта?", "answer": "Предсказание делается путём усреднения по всем возможным значениям параметров с учётом их апостериорного распределения, что даёт не только точечную оценку, но и меру неопределённости.", "topic": "bayesian_approach"}
{"question": "Почему байесовский подход удобен для дообучения модели при поступлении новых данных?", "answer": "Потому что апостериорное распределение, полученное на старых данных, автоматически становится априорным для новых, и модель можно обновить без полного переобучения.", "topic": "bayesian_approach"}
{"question": "Что такое обоснованность модели (marginal likelihood) и зачем она нужна?", "answer": "Обоснованность — это вероятность данных при заданной модели, проинтегрированная по всем параметрам; она используется для сравнения моделей с учётом их сложности и качества описания данных.", "topic": "bayesian_approach"}
{"question": "Как байесовский подход формализует принцип бритвы Оккама при выборе модели?", "answer": "Более простые модели получают преимущество, если они достаточно хорошо объясняют данные, потому что сложные модели «растягиваются» на слишком много возможных исходов и дают меньшую обоснованность.", "topic": "bayesian_approach"}

