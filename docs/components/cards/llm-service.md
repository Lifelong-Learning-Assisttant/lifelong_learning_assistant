# LLM Service - Component Card

**–°—Ç–∞—Ç—É—Å:** üìã –ó–∞–ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ  
**Owner:** @team-ai  
**–í–µ—Ä—Å–∏—è:** 1.0  
**–î–∞—Ç–∞:** 2025-11-02

## –û–ø–∏—Å–∞–Ω–∏–µ

–ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ (–ª–æ–∫–∞–ª—å–Ω—ã–µ –∏ –æ–±–ª–∞—á–Ω—ã–µ –º–æ–¥–µ–ª–∏). –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤ –∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º.

## –û—Å–Ω–æ–≤–Ω—ã–µ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å—ã

### API
- `POST /api/llm/generate` - –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
- `POST /api/llm/embed` - –°–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
- `GET /api/llm/models` - –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤
- –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ª–∏–º–∏—Ç–∞–º–∏ –∏ –∫–≤–æ—Ç–∞–º–∏

## –ö–ª—é—á–µ–≤—ã–µ –º–µ—Ç—Ä–∏–∫–∏

- **Generation latency:** < 3s –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
- **Token usage:** –∫–æ–Ω—Ç—Ä–æ–ª—å –ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è
- **Success rate:** > 99% —É—Å–ø–µ—à–Ω—ã—Ö –≥–µ–Ω–µ—Ä–∞—Ü–∏–π
- **Cost per request:** –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –∑–∞—Ç—Ä–∞—Ç

## –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏

### –ö—Ä–∏—Ç–∏—á–Ω—ã–µ
- –ú–æ–¥–µ–ª–∏ LLM (–ª–æ–∫–∞–ª—å–Ω—ã–µ/–æ–±–ª–∞—á–Ω—ã–µ)
- –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º

### –í–∞–∂–Ω—ã–µ
- User Storage (–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –º–æ–¥–µ–ª–∏)
- Rate limiting —Å–µ—Ä–≤–∏—Å

## –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã

- **–õ–æ–∫–∞–ª—å–Ω—ã–µ:** Ollama, vLLM, LM Studio
- **–û–±–ª–∞—á–Ω—ã–µ:** OpenAI, Anthropic, Cohere
- **–°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ:** –ª–æ–∫–∞–ª—å–Ω—ã–µ fine-tuned –º–æ–¥–µ–ª–∏

---

*–ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: [../deep/llm-service.md](../deep/llm-service.md)*